{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 11166525.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=288, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor:    Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0180 Acc: 0.1200\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 2/30 Train Loss: 0.0180 Acc: 0.1196\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 3/30 Train Loss: 0.0180 Acc: 0.1188\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 4/30 Train Loss: 0.0180 Acc: 0.1183\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 5/30 Train Loss: 0.0180 Acc: 0.1192\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 6/30 Train Loss: 0.0180 Acc: 0.1216\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 7/30 Train Loss: 0.0180 Acc: 0.1197\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 8/30 Train Loss: 0.0180 Acc: 0.1202\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 9/30 Train Loss: 0.0180 Acc: 0.1182\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 10/30 Train Loss: 0.0180 Acc: 0.1194\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 11/30 Train Loss: 0.0180 Acc: 0.1194\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 12/30 Train Loss: 0.0180 Acc: 0.1202\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 13/30 Train Loss: 0.0180 Acc: 0.1193\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 14/30 Train Loss: 0.0180 Acc: 0.1186\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 15/30 Train Loss: 0.0180 Acc: 0.1193\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 16/30 Train Loss: 0.0180 Acc: 0.1203\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 17/30 Train Loss: 0.0180 Acc: 0.1196\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 18/30 Train Loss: 0.0180 Acc: 0.1192\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 19/30 Train Loss: 0.0180 Acc: 0.1192\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 20/30 Train Loss: 0.0180 Acc: 0.1200\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 21/30 Train Loss: 0.0180 Acc: 0.1191\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 22/30 Train Loss: 0.0180 Acc: 0.1202\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 23/30 Train Loss: 0.0180 Acc: 0.1178\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 24/30 Train Loss: 0.0180 Acc: 0.1196\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 25/30 Train Loss: 0.0180 Acc: 0.1185\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 26/30 Train Loss: 0.0180 Acc: 0.1186\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 27/30 Train Loss: 0.0180 Acc: 0.1200\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 28/30 Train Loss: 0.0180 Acc: 0.1194\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 29/30 Train Loss: 0.0180 Acc: 0.1202\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n",
      "Epoch: 30/30 Train Loss: 0.0180 Acc: 0.1202\n",
      "Begin test......\n",
      "Test Loss: 0.0182 Acc: 0.1224\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1195, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "input_d = input.to(device)\n",
    "m = nn.Softmax(dim = 1)\n",
    "output_d = model(input_d)\n",
    "probabilities = m(output_d)\n",
    "predict_label = torch.argmax(probabilities)\n",
    "probabilities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2OElEQVR4nO3de1hU9fY/8PegMkHAKKJcjqB4g7yAhkp8NfNCKlbeyGPp+Yba0TQ0L1lG38rMCs1u2lG08midJE3zUpZ4QUFNoUAQL8lRDgYeAdNyIExU2L8/+Dk1irIXMH4A36/nmeeBmTVr1p49zGLP3rO2QdM0DURERLeZneoCiIjozsQGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESbEBERKREQ9UFXK+srAxnzpyBs7MzDAaD6nKIiEhI0zQUFRXBy8sLdnY3386pdQ3ozJkz8Pb2Vl0GERFVU25uLlq0aHHT223WgJYsWYKFCxciPz8fgYGB+OCDD9CjR49K7+fs7AwAeA+Ag87HkiyEtLVJcp8W5j4viJXWbRbEXhXmlr5oHAWxV4S5Gwli3YW5XQSx0uekSBhfIIi9KMwtIXnNAsApQaxkXQKy5ZTmlv4tFwpibfn3kyvMnSqILRPmBv54P78ZmzSgtWvXYubMmVi2bBmCg4Px/vvvY+DAgcjMzETz5s1ved9rH7s5QH8Dkry47hbESnNLXiiA7A9ImlvyRm7LN32g9jQgJ2FuSbz0OZEOYJQ2LFuRNjejIFb6HJbaMLc0XvJGastapG/ott7JUdluFJschPDuu+9iwoQJGDduHDp06IBly5bB0dER//znP23xcEREVAfVeAO6fPkyUlNTERoa+seD2NkhNDQUBw4cuCG+pKQEhYWFVhciIqr/arwBnTt3DqWlpXB3t/7E3d3dHfn5+TfER0dHw2QyWS48AIGI6M6g/HtAUVFRMJvNlkturnQ3GhER1UU1fhCCm5sbGjRogIIC6+N2CgoK4OHhcUO80WiE0SjZVUlERPVBjW8B2dvbIygoCPHx8ZbrysrKEB8fj5CQkJp+OCIiqqNschj2zJkzERERgW7duqFHjx54//33UVxcjHHjxtni4YiIqA6ySQMaNWoUfv75Z7zyyivIz89Hly5dEBcXd8OBCUREdOcyaJom/U6cTRUWFsJkMuH/ANyl8z6Sb/L7CetpI4g9J8wt+VKfmw1zS78YlyWMl3y5VLqckvjWwtzS50VC+oXOI4LYHGFuyRcfpLkl8bb8gqa/MLd0/UjiJVNKANlySv82U4TxUmazGS4uN58povwoOCIiujOxARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESNpkFVxNKIRuxo5dkLAwgG4MhHd9hslEd0tzSun2E8ZIRRbYcgXJemFvynDvYMDcge91KxvYAwEphfF30tTC+gzC+syBW+hp3FMRK/u4BQDKds6DyEDFuARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESbEBERKQEGxARESlRa2fBNYF8vpYekrlKANDaBjVUhS2ei9vFUxDb9Vlh8k36Q1dkyVJL6pa+rnKE8ZL5bnfCbDdbO2bDeF9hbj9BrHTGoLcg1iyI1QCU6IjjFhARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERK1NpRPBKS8RPSURXnBLHScTm5gljJyAwAKBTEXhHmlvKWzLR5W88Ajz+516g7NHeMLPX3gljJ6wQANgjj6y43Qaz0WaybsoXxkmelqzC35H1CMm6Ko3iIiKhWYwMiIiIl2ICIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhIiVo7C+4UAL1Tvr4V5DUL63hUEPugMLdkStbvwtySmXfSWXCSmVAAkJanP/bBh/XPdgOAFd/oj31XlBkoEsbfGXyE8ZJXy0Vhbml83SR5HUr/Nj0EsZJmUQrgVx1x3AIiIiIlarwBvfrqqzAYDFYXf3//mn4YIiKq42zyEVzHjh2xc+fOPx6kYa39pI+IiBSxSWdo2LAhPDwkny4SEdGdxib7gE6cOAEvLy+0bt0aY8aMQU5Ozk1jS0pKUFhYaHUhIqL6r8YbUHBwMFatWoW4uDjExMQgOzsb999/P4qKKj6WIzo6GiaTyXLx9pae+5OIiOqiGm9AYWFhGDlyJAICAjBw4EB8++23uHDhAr744osK46OiomA2my2X3FzJiaqJiKiusvnRAY0bN0b79u1x8uTJCm83Go0wGmXf/SAiorrP5t8D+u2335CVlQVPT09bPxQREdUhNd6AZs2ahcTERJw6dQr79+/H8OHD0aBBAzz++OM1/VBERFSH1fhHcKdPn8bjjz+O8+fPo1mzZujVqxeSkpLQrFkzUZ5/AjDojL0krlK/JYJY6eETkjE/0lE8DjaKBQDpcYqSsUBTBKN1AOBzQax05NCdwrdNG92xD/YKFuX+8JNYaTlUDZnC+E6C2HPC3HrUeANas2ZNTackIqJ6iLPgiIhICTYgIiJSgg2IiIiUYAMiIiIl2ICIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUsLmp2OoqqbQ3x1P27IQgTRh/ABB7EVhbgkXYbx03tQyQWycMLe7IPZRf1nuz47L4uuq7Kws3bGPPhshyn1QMAouhcP6qi1bGC+ZX+koiC3VGcctICIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSgg2IiIiUYAMiIiIl2ICIiEgJNiAiIlKCDYiIiJSotaN4vvn6bTjf7aArtm2/SBtXo0/XRrL4HMHoEckYDACQlGIW5u7TSxY/bJ/wAQTeGN1Gd+wVR/2xAPDZ8e3Scuq912e9Ioq/N7iz7tiUfYel5VA15QtimwpiDTrjuAVERERKsAEREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkRK2dBde692i4uLjoiu0wTP9QtWObpovqeOejDbpjn8wbIcq9WTBWK0+UWTbfbba2Uph9rChaE8Quu8dLlPvRXrN1x766eIUoN91IML4QAGC+qP8e7YWzFP8tLYZu8G9BrK8gtkxnHLeAiIhICTYgIiJSgg2IiIiUYAMiIiIl2ICIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlKi1s+CAu///pXLHNi3TnXXE2ydEVQQ/1FZ3rGm3vyi3Gcd1x7qJMgOTBbGzhbPdbMnfrZco3uRzr+5YP58EWTHHk2Xxd4CdSQdE8Z/Hrtcd23PAMFHuZ+bPF8VT9WTbICe3gIiISAlxA9qzZw8eeeQReHl5wWAwYNOmTVa3a5qGV155BZ6ennBwcEBoaChOnJBtdRARUf0nbkDFxcUIDAzEkiVLKrz9rbfewuLFi7Fs2TIkJyfj7rvvxsCBA3Hp0qVqF0tERPWHeB9QWFgYwsLCKrxN0zS8//77eOmllzB06FAAwKeffgp3d3ds2rQJjz32WPWqJSKieqNG9wFlZ2cjPz8foaGhlutMJhOCg4Nx4EDFOy9LSkpQWFhodSEiovqvRhtQfn4+AMDd3d3qend3d8tt14uOjobJZLJcvL29a7IkIiKqpZQfBRcVFQWz2Wy55Obmqi6JiIhugxptQB4eHgCAgoICq+sLCgost13PaDTCxcXF6kJERPVfjTYgX19feHh4ID4+3nJdYWEhkpOTERISUpMPRUREdZz4KLjffvsNJ0+etPyenZ2N9PR0uLq6wsfHB9OnT8frr7+Odu3awdfXFy+//DK8vLwwbNiwmqybiIjqOHEDSklJQd++fS2/z5w5EwAQERGBVatW4fnnn0dxcTEmTpyICxcuoFevXoiLi8Ndd91Vc1XfIEd3ZFZWniizh6f+UTwIHiDKHSwYxdNalBnoIIg1GAyi3JqmyYoxX9Yd6t3GUZbb8Zzu0ElfvClK/UHjWN2xx0SZ6y7HzveJ4k2e3+mO/X73Pmk5VMeJG1CfPn1u+QZkMBjw2muv4bXXXqtWYUREVL8pPwqOiIjuTGxARESkBBsQEREpwQZERERKsAEREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpIR4FE/tdFF3ZObBw6LMnrhfd6w52SzKLeEmjH9JEDtamPvIx7tkdzg4R3foxE9k88D2vzBYf7CppSj33Nce0h078pVvRLlrkxdfsN3YrDyz/r/NDzdtslkdVDtxC4iIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSgg2IiIiUYAMiIiIl6skoHv3+7+8RonhHQaxhzCei3N0EsVsbiVLD/4osXmLZ4nGi+ItZObpjl7zWV1aMfxtZvMCjzy7UHftIrGyE0LfHZWObSkXRMk09W9ssd27eOZvlprqPW0BERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERK3HGz4Ib1vVt1CRYpgtj1wtluwbJwkSWH9c92A4DegtiuL++SFSOQd/gnUfz/zVuvO7ZPr5Gi3J6eh0XxH+5OFsVLXBRNPJTZl6x/Od09/UW5C/KOS8uhWoZbQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESbEBERKQEGxARESlRL0bx+Po8ozu2qQ3rcB/wtii+YPss3bGbhbVckUxXuSjL7S4Lh6e/7Ua9SPxf1Aei+IPHs3TH7sjaJMp9WhRtW5mxE3XHHmljFuUePED/UKiX588X5abbq5sgthRAmo44bgEREZESbEBERKSEuAHt2bMHjzzyCLy8vGAwGLBp0yar28eOHQuDwWB1GTRoUE3VS0RE9YS4ARUXFyMwMBBLliy5acygQYOQl5dnuXz++efVKpKIiOof8UEIYWFhCAsLu2WM0WiEh4dHlYsiIqL6zyb7gBISEtC8eXP4+flh8uTJOH/+/E1jS0pKUFhYaHUhIqL6r8Yb0KBBg/Dpp58iPj4eCxYsQGJiIsLCwlBaWlphfHR0NEwmk+Xi7e1d0yUREVEtVOPfA3rssccsP3fu3BkBAQFo06YNEhIS0L9//xvio6KiMHPmTMvvhYWFbEJERHcAmx+G3bp1a7i5ueHkyZMV3m40GuHi4mJ1ISKi+s/mDej06dM4f/48PD09bf1QRERUh4g/gvvtt9+stmays7ORnp4OV1dXuLq6Yu7cuQgPD4eHhweysrLw/PPPo23bthg4cGCNFk5ERHWbuAGlpKSgb9++lt+v7b+JiIhATEwMMjIy8Mknn+DChQvw8vLCgAEDMG/ePBiNxpqr+joPjpytO/a8bJQVJNttO1c/K8rduZn+WXA7HHuJcl9stE93bG9RZmCPML5Hr5G6Y88lp4pyf5+8Q3dsXs7HotyHsoQvljrqjc7ndMd+GzNOlPu8Sf/rNrCNmyj3oSz9dVPF5ghi9U9GBC5D3yw4cQPq06cPNE276e3btm2TpiQiojsQZ8EREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkhEG71VwdBQoLC2EymWA2m3WfmmHHcf35GzWS1dOnjf7YK7LUsDcYhPfQL+a1D3XHZu6bKMr9/nZZLa6C2F9kqakCfxMOnv8szzZ1AICzINbTJPvj/LdZ+hdX/40Sxgve3nBQEHsVwE6g0vdxbgEREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkREPVBdSEB/31x6YJc58TxJqEueEfoT/2+Cei1N8evKg7tmdwtCh34OEoUfwhG4566SCIPSbMLRkh9PjfBesSwJKPZetTwifYRxTvuylHd2y2sJYiSewdMlqnvTB+iiBWOIUJ+tc8ECyILUH5KJ7KcAuIiIiUYAMiIiIl2ICIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhICYOmaZrqIv6ssLAQJpMJZrMZLi4uNZ5fMvsIkM13k86C+995u3THfvZKf2H20fpDG+mfGwcAIb1kE6faXDysO/az5H2i3JJ5bb+IMgPjgjvrjv1nUoYot8HQTFiN/qmELYSZvRvpjzV7uolyH8uRTFO8M2wXxvsJYv8jzC15PzwiiC0BsBio9H2cW0BERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREp0VB1ATeT9MVq3O3ooCu25+ixuvP6SAu5IogVjDQBAD9/f9kdBFr0elB37Hd7x4pytzQYRPEHRNEysvE6jqLof+6VjdeRePHlJaL4N+eN0h17WljLaclrnKN1qu1T2csQEEzK2ixMLVn1l4S59eAWEBERKSFqQNHR0ejevTucnZ3RvHlzDBs2DJmZmVYxly5dQmRkJJo2bQonJyeEh4ejoKCgRosmIqK6T9SAEhMTERkZiaSkJOzYsQNXrlzBgAEDUFxcbImZMWMGvv76a6xbtw6JiYk4c+YMRowYUeOFExFR3SbaBxQXF2f1+6pVq9C8eXOkpqaid+/eMJvNWLFiBWJjY9GvXz8AwMqVK3HPPfcgKSkJ9913X81VTkREdVq19gGZzWYAgKtr+VlZUlNTceXKFYSGhlpi/P394ePjgwMHKt4VXVJSgsLCQqsLERHVf1VuQGVlZZg+fTp69uyJTp06AQDy8/Nhb2+Pxo0bW8W6u7sjPz+/wjzR0dEwmUyWi7e3d1VLIiKiOqTKDSgyMhJHjhzBmjVrqlVAVFQUzGaz5ZKbm1utfEREVDdU6XtAU6ZMwZYtW7Bnzx60aPHHCYA9PDxw+fJlXLhwwWorqKCgAB4eHhXmMhqNMBqNVSmDiIjqMNEWkKZpmDJlCjZu3Ihdu3bB19fX6vagoCA0atQI8fHxlusyMzORk5ODkJCQmqmYiIjqBdEWUGRkJGJjY7F582Y4Oztb9uuYTCY4ODjAZDLhySefxMyZM+Hq6goXFxdMnToVISEhPAKOiIisiBpQTEwMAKBPnz5W169cuRJjx44FALz33nuws7NDeHg4SkpKMHDgQCxdurRGiiUiovrDoGmaprqIPyssLITJZAIQCKCBrvtoWqrtCsoTxHrKUj/w9GrdsXti/ibK/eLSU7pj35jcUpRbyu+v+v8BadjIJMr90EMjdce+MdpelFs42k/kiGC+FwB0vn+R/uCD02XJqQZI5jqahbklr8QcYW4JSR0agKswm81wcXG5aRRnwRERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESbEBERKRElU7HcHt0AKBvdIpkqskVYRWOgskw0tEtjpLkQrYeryOR+cXTumMNE34U5T42/xvdsQu/6SvKjeOSsSbnZLkPC+OvLJDF10nSv6B7BbE+wtzSdwrJHC5pLZLn5aAwt6RuyVyyKwDWVRrFLSAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSgg2IiIiUYAMiIiIlavEsOEfonQV390D9Wf/2kayK2YKxTZ1kqfHSCw/rj/17iTB77WHot1d/8O7etivksO1Sy0nnnklmdkk5CmI726yKKkxTtGFuf2G8ZCKlcA6gKLfkOZHGS55DTVcUt4CIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSohaP4mkB4C59oduH6876WUs3URUJS/XP7vlysig1/vevs3TH/mfX27LkNjTkG+Edds8RBMvWj2w8iHRMyRVBrHS8inQ0jNmGuSWjXvKEuSUjhCTPNyBbn9J17y2MLxTGSzQVxErWJQCcF8QOFdbxeaVR3AIiIiIl2ICIiEgJNiAiIlKCDYiIiJRgAyIiIiXYgIiISAk2ICIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSohbPghsPwEVnrGSG1CZRFaefnqY7NjRvkSi3fN5U7fD1w82E97hXENtGmFs640siRxArnWMmndllSyYbxQKAjw1zS+YG9hTmlr6uJDPypLkl8/Skr6t++kMHCNJeLQR2VR7GLSAiIlJC1ICio6PRvXt3ODs7o3nz5hg2bBgyMzOtYvr06QODwWB1mTRpUo0WTUREdZ+oASUmJiIyMhJJSUnYsWMHrly5ggEDBqC4uNgqbsKECcjLy7Nc3nrrrRotmoiI6j7RPqC4uDir31etWoXmzZsjNTUVvXv3tlzv6OgIDw+PmqmQiIjqpWrtAzKby0+S5erqanX96tWr4ebmhk6dOiEqKgoXL958x1hJSQkKCwutLkREVP9V+Si4srIyTJ8+HT179kSnTp0s148ePRotW7aEl5cXMjIyMHv2bGRmZmLDhg0V5omOjsbcuXOrWgYREdVRVW5AkZGROHLkCPbt22d1/cSJEy0/d+7cGZ6enujfvz+ysrLQps2Nh9hGRUVh5syZlt8LCwvh7V03D08mIiL9qtSApkyZgi1btmDPnj1o0aLFLWODg4MBACdPnqywARmNRhiNxqqUQUREdZioAWmahqlTp2Ljxo1ISEiAr69vpfdJT08HAHh6Sr5MRURE9Z2oAUVGRiI2NhabN2+Gs7Mz8vPzAQAmkwkODg7IyspCbGwsBg8ejKZNmyIjIwMzZsxA7969ERAQYJMFICKiuknUgGJiYgCUf9n0z1auXImxY8fC3t4eO3fuxPvvv4/i4mJ4e3sjPDwcL730Uo0VTERE9YP4I7hb8fb2RmJiYrUK+oMJ+mfBtRbklcymAoDtuiOL5t0vyuz8TLywFtswTNgrvMc5YbxkTpa/MLdk9tVBYW4JyVwyW5PWIomX5pbMAexUeYgVSS3S1+z3wnjJLEDpvLYn9Ye2aStLLflz2y2IvXWrsOAsOCIiUoINiIiIlGADIiIiJdiAiIhICTYgIiJSgg2IiIiUYAMiIiIl2ICIiEgJNiAiIlKCDYiIiJSo8vmAbM8M3fMc4CjIKx31YhLEZokyFy2eoz94UbQot8i6BOEdegnjbfccAp0FsdIxMpJaJMtYlXhbjsux5d+PWRArHX8jGd0jGZUDyMfl5AhiBaN1AMBHMF5HOnHom3cEwZJ1WaIriltARESkBBsQEREpwQZERERKsAEREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGREREStTiWXBXoX9+k2Ruk4ewDsnMLk9h7t26Iw1BP4kyn0xtqT/YHCPKLZsdJo33EeaWxEvrlsw9Sxbmlg7tkrzGpbPgJK9xad2S3NJ5bd/ZMLd0Vt/j+kMd75elzrksCF4gy41XBLHPCGI5C46IiGoxNiAiIlKCDYiIiJSoxfuAiMjaVQBlOuIuCPNK3gakbxmSfVdXhbkv2TD378L4E/pDy5oJc0v2X50R5pY4e93vDgCcq5WRDYioTrgK/W8u+bYshCq0Sn+opG/WKmuu+70BgCdQnSbEj+CI6gQ9Wz5Et1Mp5FuK1tiAiIhICTYgIiJSgg2IiIiUYAMiqsOys7Nx/PhxpKWl4ejRo3j66aernbNjx47Izs4GAHh6emLPnj2V3mfatGlwd3ev0uMtXLgQc+bMqfC2Bg0a4JVXXsGPP/6Iw4cPIy0tDcuXL4fJZMIDDzyAtLS0Kj3m7TZ06FAEBwff1sfMzs5GYGBghbd98803aN++PQBg9+7dGDp06O0szaL2HgXX0A0wuOiLvdJIkDhXWEgnQazkkFMAaKM/9GArUea2hghBdJ4ot1yWIFY6AkXynAuebwCyMT9mYW7pchoBfFbhLaNGjcKhQ4fg4+ODjIwM7N27F4cPH7bcbjAYAACapgkfE8jLy0Pv3r0rjZs+fToSEhJQUFAgfoxbWbFiBVxdXRESEoILFy4AAB599FG4urrW6OPY2rBhw5Ceno7kZOnIJtt46KGHaijTSQAVrXN9h71zC4ionsjJyUFmZibat2+POXPmYP369YiLi8ORI0fg6emJAQMGYO/evUhJSUFycjL69Oljue+cOXPw73//GykpKXjssccs17ds2RK//vqr5ff77rsPe/fuRXp6Og4dOoQhQ4bg5ZdfhpeXF9auXYu0tDQEBgaiYcOGiI6ORnJyMtLS0rB27Vo0btwYAODh4YG4uDgcPXoUO3bsQIsWLSpcnjZt2mDkyJEYN26cpfkAwPr16y1baNc0aNAAcXFx+OGHH3DkyBGsXr0ajo7ls//atm2Lffv2IT09HRkZGZg3bx4A4OGHH8ahQ4eQlpaGw4cPY8iQIZU+x48//jiSkpJw8OBBpKen4+GHH7bcdv2WxLp16xAREYGwsDAMGTIEzz33HNLS0vDkk08CAGbNmoUjR44gIyMDn332GVxcXCzrYu3atfjqq6+QmZmJr7/+Gh07dkRcXBwyMzMRGxtr+aeiWbNm+PLLL5GRkYHDhw9j4sSJVvWOGTMGKSkpOHHiBGbNmmW5/mZbR05OTvjwww+RnJyMQ4cOYfny5WjUSPIPvgwbEFE90alTJ/j7++PQoUMAgJCQEDzxxBPo2LEjjEYjXn31VQwePBjdunXD6NGjERsbC3t7ewwePBgjR45EUFAQunXrhlatWlWYv0mTJti0aROioqLQpUsXdOnSBXv37sW8efNw5swZjBo1Cl27dsWhQ4fw3HPPobi4GMHBwejatSsOHz6M119/HQCwePFifP/99+jYsSMiIiLQv3//Ch/v3nvvxYkTJ3D+/PlKl720tBSjR49G9+7d0alTJ5jNZkydOhUAMGXKFGzZsgVdunRBQEAA3n33XQDA66+/jqeeegpdu3ZFQEAAEhMTAQBPPfUU5s6dW+HjbNu2Dffddx/uvfdeDB06FB999BHs7e1vWdvWrVvx1VdfYeHChejatStWrFiBQYMGYfz48ejZsycCAgJQXFyM+fPnW+7TrVs3PPHEE/Dz84OzszM+/vhjPProo+jQoQPuuecehIWFAQA++OADZGZmIiAgAP369cNLL71k9VGfu7s7unXrhvvuuw9Tp05FSEjILWt95513sHfvXgQHByMwMBB2dnaYNm1aJc9+1dXej+CISJe1a9fi999/x8WLFzF+/HicPHkSAPDtt9/i7Nnyb68PGjQIbdu2tdqfU1ZWBh8fH/Tv3x9ffPEFioqKAADLly9Hr169bnickJAQZGZmYt++fQDKP9L789bRnw0bNgwmkwnh4eEAAHt7e5w6dQoA0L9/f8t/42fOnMFXX31V7efAYDBgxowZeOihh9CwYUOYTCbs378fALBnzx4sXLgQTk5OSExMxM6dOwEA8fHxWLRoEdavX4/t27dbGvfy5ctv+ji+vr5YvXo1WrRogatXr8LV1RW+vr7IzMwU1RsaGoq1a9fCbC7/6DYmJgbr1q2z3L59+3bLVt/BgwdRUlKC3377DQCQlpaGdu3aWfIEBQUBAH7++Wds2LABoaGhlo/6VqxYAQA4f/685bYDBw7ctK5hw4YhJCQEM2fOBAA4ODigtLRUtGwSbEBEddy1fUDXu/aGBZS/Qe/YsQNjxoypNF9V9hVdz2AwYOrUqdixY0eVH+/gwYNo164dXF1d8csvv9wyx+jRo9GvXz888MADKCoqwtSpU9GvXz8AwIYNG7B//348+OCDmDJlCqZPn46HHnoIzz77LDp06IC+ffvik08+werVq7Fw4cJbPs6aNWvwwgsv4MsvvwRQ/sZ+1113AQCuXr2KBg0aWGKvXa/H9c/BpUt/jEsoLS294feGDSt+665s3VV2u8FgQHh4OE6cEIwWqgZ+BEd0B9i2bRtCQ0PRuXNny3Xdu3cHAOzcuRMjR46Ek5MTANywH+Ga/fv3o127dpatI4PBgCZNmgAACgsLYTL9cWDFpk2bMGPGDDg4OAAo/0+6Q4cOlscbP348gPL9QTfb95KVlYUvv/wSK1assMo9YsQI+Pr6WsU2adIE586dQ1FREZycnDB27FjLbW3btkVBQQH+9a9/4fnnn8d9990HAPDz88OxY8ewZMkSxMTEWK6/lSZNmlj2P40ZM8bqYIiTJ09aPv5q1aqV1Vbk9c/Pzp078de//hXOzuVjbJ566ils37690se/3s6dOzFhwgQAgJubG0aMGGHV9K89D02aNMHw4cMRHx9/y3ybNm3C7NmzLY20cePGaNNGevCOftwCIroDZGVlYfTo0Vi+fDkcHR1hb2+PtLQ0jBkzBlu3bkWPHj1w8OBBFBYWYuvWrRXmuHDhAoYPH4533nkHzs7OKCsrw8svv4wtW7Zg8eLF+Oijj3Dx4kWMHTsWCxYsgNFoRHJysuW/7gULFuDYsWOYNm0aVq1ahaNHj+K///0vdu3addO6x48fj5deegnJycm4evUq7OzssGfPHsTHx8PH54+jFD/99FMMHToUx48fx88//4y9e/eiZcvykzI++uij+Nvf/obLly/Dzs4OkyZNAgC8+eab8PPzw+XLl3Hx4kVMnjwZQHkz8PLyqvDQ8GnTpmH9+vW4cOECdu3ahZ9++uNEkW+99RbWrl2LjIwMHD161OqIt3/9619YtWoVhg0bhiVLlmDFihXo1KkTDhw4gLKyMmRkZFTpEPpnnnkGMTExyMjIgMFgwBtvvIHvv//ecvvPP/+MlJQUmEwm/OMf/7jlx28AMGPGDMyfPx/p6ekoKyvD1atX8fzzzyMrS3Ikq34GrSa2t2uQ5T+FhmbBYdhfCB7h+8pDrEgOw/6PMLdkpcYKc0sOw/5EmNuWpIcnS75bIf1PTnIG1cOVh1ipucOwidTphoqHkV4FsBdms9lydF9F+BEcEREpwQZERERKsAER1WE1MYonIiICGzduFN9vzpw5eO+99yq87amnnrIcav3n/EFBQVizpvy8MiaTCbNnzxY/7vUcHBwQGxuLEydOIDMz03Lod0XWrVuH//73v9A0zeqgAE9PT8TFxeH48eM4dOgQ1q9fDzc3t2rXRrfGBkRUx137AmhYWBjefPNNqyPdgPKj1a59c/52Wb58Od5+++0brk9NTbVMWmjcuDFeeOGFaj/WrFmzUFJSgnbt2mHgwIFYunTpTUf1LFu2DF26dLnh+tLSUsybNw/+/v4IDAzEf/7zn0oPyabqq71HwUnPoKubdO6Zt02qKCfZyS0dZCg5sEA6akNyimAp6Uw1+aGr+kmeF09hbn9hfOUH5Px5FM+IESPQuXNnODk5wdvbGw8++CD69euH5557DgCQm5uLiRMn4syZ8rOsuri4YPPmzWjbti3OnTuHJ554Aj/99BM6deqEmJgYODo64q677kJsbCzeeOMNy2N6e3sjPj4eXl5eOHHiBMaOHYtffvkFc+bMQePGjTFjxgyrGh944AG8//776Nq1K5YtWwZnZ2ekpaXh6tWrmDRpEj777DPcc889lvjvvvsO8+bNQ1xc3E2Xe9SoUZbxNqdOnUJCQgKGDx9u+RLmn93sMOSzZ89avrQLAMnJyZgyZUplTzkhpVr35hYQUT1xq1E8TZo0wcKFCxEWFobAwEDs378fH3/8seW+PXv2xOzZs9GxY0ds2bIFH374IYDyN/T+/fsjKCgIQUFBCA8Ptxr1cv/992P06NG45557kJubi+joaN31Tpo0CUVFRejatSu6d++O1NRUnD9/Hg8++CAAoEuXLmjWrBni4uIwd+5cPPXUUxXm8fHxsToc+tSpU1aHaEvZ2dlhypQp2Lx5c5VzkD6iBhQTE4OAgAC4uLjAxcUFISEhVt8ZuHTpEiIjI9G0aVM4OTkhPDy8xqfjEpG1a0NAly9fftNRPH379kVcXJxli2fp0qXo168f7OzK3wL279+P48ePAwA+/PBD9OnTB3Z2dnBwcMDHH3+MjIwMJCUloWXLllYfYX3zzTeWv/EPP/wQoaGh1VqWRYsWWbY8IiMjsXTpUgDl+5tuNSKnJi1duhS//vorFi1adFse704makAtWrTA/PnzkZqaipSUFPTr1w9Dhw7F0aNHAZR/ienrr7/GunXrkJiYiDNnzmDEiBE2KZyIyl3bB9SzZ0/LiBjAehTP9fR+/e/NN9/EuXPn0LVrV3Tp0gUJCQm3HDFT3a8VbtiwAQEBAejSpQuGDBmClStXVnqfnJwcy5dOgfIpBDk5OVV6/MWLF8Pb2xujRo2qkZFEdGuiBvTII49g8ODBaNeuHdq3b4833ngDTk5OSEpKgtlsxooVK/Duu++iX79+CAoKwsqVK7F//34kJSXZqn4i0mH37t0YNGgQPD3L91VNmjQJ8fHxKCsrA1D+cZ2fnx8A4O9//zt2796NsrIyNGnSBKdPn0ZpaSnat29v+XjsmsGDB6N58+aW+10b9KlHYWEhHBwcrMb9l5aWYtmyZfjqq6+wceNGy7DOW1m3bp1lukGrVq3Qp08fbNq0SXcd1yxatAht27bF8OHDceWKLfdz0jVV3gdUWlqKNWvWoLi4GCEhIUhNTcWVK1esNsH9/f3h4+Nzy/EPJSUlKCwstLoQUc06evQonnvuOcTFxeHQoUO4//77LTPEgPKP4BYsWIAjR45gyJAhlv0tr7/+OsaNG4dDhw5h/vz5N4zN2bt3L2JjY/Hjjz+iZcuWePHFF3XX9Ouvv+LTTz9FRkYGfvjhB8v1K1aswF/+8hf84x//sFx3q31ACxcuhIODA06ePIlt27ZhypQpllM4XH9qhS1btiA3N9fynOzevRsA8D//8z945pln0KpVK8s5jDZs2KB7WahqxKN4Dh8+jJCQEFy6dAlOTk6IjY3F4MGDERsbi3HjxqGkpMQqvkePHujbty8WLFhQYb5XX331JufeMEPPkT/lJKN4pDsWewhiKz9viTXJEXnSUS+SMy/WpqPgapPadhTceuF96qbw8HBMnjy52vuTSL3KRvGID8P28/NDeno6zGYz1q9fj4iICMuJnKoiKirKcu4JoHyz3Nvbloc+E1FttXXrVrRv3x7Dhw9XXQrdBuIGZG9vj7Zt2wIo/1bzDz/8gEWLFmHUqFG4fPkyLly4YDn1LgAUFBTAw8PjpvmMRiOMRqO8ciKqd66d6ZPuDNX+HlBZWRlKSkoQFBSERo0aWX3RKzMzEzk5OZWeBpaIiO48oi2gqKgohIWFwcfHB0VFRYiNjUVCQgK2bdsGk8mEJ598EjNnzoSrqytcXFws5yDXc6InIiK6s4ga0NmzZ/HEE08gLy8PJpMJAQEB2LZtm+XQzPfeew92dnYIDw9HSUmJZS5T1eQBuPn3GKxJd6JLHLFh7os2igVkz8mdclCBlOR5kX7vRBrfWBhPVPvV3hPS4TgqPtFRRSRHfEmPJJLMa5OSNBXpUXDHBbFsQLVfEwC/qi6CSKTGj4IjIhUaoLwJ6fl/8WFh7p6C2NPC3JJ/DqUTiCW1jJKlbiWc4NJLECv9UCVd8n2kLysPsSI55cQ+Ye7KsQER1RkNdMa5C/O2t0EN1/xbECvdEpd8765l5SF/dte9snjJU35KlhpIFcRKP7GRnhq+ZnEaNhERKcEGRERESrABERGREmxARESkBBsQEREpwQZERERKsAEREZESte57QH8MZtA7hgeQTRSQftfgsjBeQlJLqTB3rRpwQdVWJogtqTzESrEg9ndhbslrXPq3KfmbENZdKjwxpuQpl37fVlS79H3CtlNQKhu0U+tG8Zw+fZrnAyIiqgdyc3PRokWLm95e6xpQWVkZzpw5A2dnZxgMBsv1105Ul5ube8vZQnUdl7P+uBOWEeBy1jc1sZyapqGoqAheXl6ws7v5np5a9xGcnZ3dLTumi4tLvV7513A56487YRkBLmd9U93lLB8qfWs8CIGIiJRgAyIiIiXqTAMyGo2YM2cOjEaj6lJsistZf9wJywhwOeub27mcte4gBCIiujPUmS0gIiKqX9iAiIhICTYgIiJSgg2IiIiUqDMNaMmSJWjVqhXuuusuBAcH4/vvv1ddUo169dVXYTAYrC7+/v6qy6qWPXv24JFHHoGXlxcMBgM2bdpkdbumaXjllVfg6ekJBwcHhIaG4sSJE2qKrYbKlnPs2LE3rNtBgwapKbaKoqOj0b17dzg7O6N58+YYNmwYMjMzrWIuXbqEyMhING3aFE5OTggPD0dBQYGiiqtGz3L26dPnhvU5adIkRRVXTUxMDAICAixfNg0JCcHWrVstt9+udVknGtDatWsxc+ZMzJkzBwcPHkRgYCAGDhyIs2fPqi6tRnXs2BF5eXmWy759+1SXVC3FxcUIDAzEkiVLKrz9rbfewuLFi7Fs2TIkJyfj7rvvxsCBA3Hp0qXbXGn1VLacADBo0CCrdfv555/fxgqrLzExEZGRkUhKSsKOHTtw5coVDBgwAMXFfwwynTFjBr7++musW7cOiYmJOHPmDEaMGKGwajk9ywkAEyZMsFqfb731lqKKq6ZFixaYP38+UlNTkZKSgn79+mHo0KE4evQogNu4LrU6oEePHlpkZKTl99LSUs3Ly0uLjo5WWFXNmjNnjhYYGKi6DJsBoG3cuNHye1lZmebh4aEtXLjQct2FCxc0o9Goff755woqrBnXL6emaVpERIQ2dOhQJfXYytmzZzUAWmJioqZp5euuUaNG2rp16ywxP/74owZAO3DggKoyq+365dQ0TXvggQe0adOmqSvKRpo0aaJ9/PHHt3Vd1votoMuXLyM1NRWhoaGW6+zs7BAaGooDBw4orKzmnThxAl5eXmjdujXGjBmDnJwc1SXZTHZ2NvLz863Wq8lkQnBwcL1brwCQkJCA5s2bw8/PD5MnT8b58+dVl1QtZrMZAODq6goASE1NxZUrV6zWp7+/P3x8fOr0+rx+Oa9ZvXo13Nzc0KlTJ0RFReHiRckpYWqX0tJSrFmzBsXFxQgJCbmt67LWDSO93rlz51BaWgp3d3er693d3XH8+HFFVdW84OBgrFq1Cn5+fsjLy8PcuXNx//3348iRI3B2dlZdXo3Lz88HgArX67Xb6otBgwZhxIgR8PX1RVZWFl588UWEhYXhwIEDaNCggeryxMrKyjB9+nT07NkTnTp1AlC+Pu3t7dG4cWOr2Lq8PitaTgAYPXo0WrZsCS8vL2RkZGD27NnIzMzEhg0bFFYrd/jwYYSEhODSpUtwcnLCxo0b0aFDB6Snp9+2dVnrG9CdIiwszPJzQEAAgoOD0bJlS3zxxRd48sknFVZG1fXYY49Zfu7cuTMCAgLQpk0bJCQkoH///gorq5rIyEgcOXKkzu+jrMzNlnPixImWnzt37gxPT0/0798fWVlZaNOmze0us8r8/PyQnp4Os9mM9evXIyIiAomJibe1hlr/EZybmxsaNGhwwxEYBQUF8PDwUFSV7TVu3Bjt27fHyZMnVZdiE9fW3Z22XgGgdevWcHNzq5PrdsqUKdiyZQt2795tddoUDw8PXL58GRcuXLCKr6vr82bLWZHg4GAAqHPr097eHm3btkVQUBCio6MRGBiIRYsW3dZ1WesbkL29PYKCghAfH2+5rqysDPHx8QgJCVFYmW399ttvyMrKgqenp+pSbMLX1xceHh5W67WwsBDJycn1er0C5Wf9PX/+fJ1at5qmYcqUKdi4cSN27doFX19fq9uDgoLQqFEjq/WZmZmJnJycOrU+K1vOiqSnpwNAnVqfFSkrK0NJScntXZc1ekiDjaxZs0YzGo3aqlWrtGPHjmkTJ07UGjdurOXn56surcY8++yzWkJCgpadna199913WmhoqObm5qadPXtWdWlVVlRUpKWlpWlpaWkaAO3dd9/V0tLStJ9++knTNE2bP3++1rhxY23z5s1aRkaGNnToUM3X11f7/fffFVcuc6vlLCoq0mbNmqUdOHBAy87O1nbu3Knde++9Wrt27bRLly6pLl23yZMnayaTSUtISNDy8vIsl4sXL1piJk2apPn4+Gi7du3SUlJStJCQEC0kJERh1XKVLefJkye11157TUtJSdGys7O1zZs3a61bt9Z69+6tuHKZF154QUtMTNSys7O1jIwM7YUXXtAMBoO2fft2TdNu37qsEw1I0zTtgw8+0Hx8fDR7e3utR48eWlJSkuqSatSoUaM0T09Pzd7eXvvLX/6ijRo1Sjt58qTqsqpl9+7dGoAbLhEREZqmlR+K/fLLL2vu7u6a0WjU+vfvr2VmZqotugputZwXL17UBgwYoDVr1kxr1KiR1rJlS23ChAl17p+nipYPgLZy5UpLzO+//649/fTTWpMmTTRHR0dt+PDhWl5enrqiq6Cy5czJydF69+6tubq6akajUWvbtq323HPPaWazWW3hQuPHj9datmyp2dvba82aNdP69+9vaT6advvWJU/HQEREStT6fUBERFQ/sQEREZESbEBERKQEGxARESnBBkREREqwARERkRJsQEREpAQbEBERKcEGRERESrABERGREmxARESkBBsQEREp8f8A9vzHX/dKGRcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.1121\n",
      "automobile: 0.1195\n",
      "bird: 0.0908\n",
      "cat: 0.1024\n",
      "deer: 0.0910\n",
      "dog: 0.0835\n",
      "frog: 0.1123\n",
      "horse: 0.0915\n",
      "ship: 0.0933\n",
      "truck: 0.1037\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[0][predict_label].item()\n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0][i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
