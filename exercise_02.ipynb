{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets #里面存在一些数据集\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image #用于打开，操作和保存图像文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), #将照片裁剪，增加四个像素点来利于提取\n",
    "    transforms.RandomHorizontalFlip(), #随机翻转一下提高随机性\n",
    "    transforms.ToTensor(), # 转化为张量\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # 归一化\n",
    "]) #首先加载参数\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), \n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train) #加载训练集\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test) #加载测试集\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # 第一个卷积层：输入通道数为3（彩色图像），输出通道数为4，卷积核大小为3x3\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "\n",
    "        # 最大池化层：窗口大小为2x2，步幅为2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 第二个卷积层：输入通道数为4，输出通道数为8，卷积核大小为3x3\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "\n",
    "        # 全连接层1：输入特征维度为8x6x6，输出特征维度为32\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "\n",
    "        # 全连接层2：输入特征维度为32，输出特征维度为10（分类数，通常对应着类别数量）\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一卷积层 + 最大池化层 + 非线性激活函数 ReLU\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "\n",
    "        # 第二卷积层 + 最大池化层 + 非线性激活函数 ReLU\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "\n",
    "        # 将特征图展平成一维向量\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "\n",
    "        # 第一个全连接层 + 非线性激活函数 ReLU\n",
    "        x = torch.relu(self.fc1(x))\n",
    "\n",
    "        # 第二个全连接层，通常用于分类任务，输出类别分数\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "#学习率调整器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 30/30 [03:27<00:00,  6.90s/it]\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS),desc=\"Loading\"):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "#     print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "#         print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "#         print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "\n",
    "probabilities = F.softmax(model(input),dim=1).cpu().detach().numpy()\n",
    "predict_label = np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.0078\n",
      "automobile: 0.0041\n",
      "bird: 0.0581\n",
      "cat: 0.3099\n",
      "deer: 0.0891\n",
      "dog: 0.3277\n",
      "frog: 0.0353\n",
      "horse: 0.0605\n",
      "ship: 0.1048\n",
      "truck: 0.0028\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[0,predict_label].item()\n",
    "image = input.cpu().numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0,i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32766294"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
