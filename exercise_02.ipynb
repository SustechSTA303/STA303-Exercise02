{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "# Evaluate the model after 1 epoch.\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    # 随机裁剪图像为32x32像素大小，并在裁剪过程中进行4像素的填充。这可以增加数据的多样性，有助于模型更好地泛化。\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    # 随机水平翻转图像，增加数据的多样性。\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize(mean, std) \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #这是第一个卷积层，输入通道数为3（因为通常是RGB图像），输出通道数为4，卷积核大小为3x3:\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        # 这是最大池化层，用于减小特征图的尺寸。池化窗口大小为2x2，步幅也为2:\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 这是第二个卷积层，输入通道数为4（来自前一个卷积层的输出通道数），输出通道数为8，卷积核大小为3x3:\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3) \n",
    "        # 这是全连接层1，接受来自卷积层的展平特征，输入维度为8x6x6（根据前面卷积和池化层的尺寸计算得到），输出维度为32:\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        # 这是全连接层2，输出维度为10，对应于CIFAR-10数据集的10个类别:\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    # 这是前向传播函数，定义了数据在模型中的前向传播路径:\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# 这行代码创建了一个学习率调度器，用于在训练过程中动态调整学习率:\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0150 Acc: 0.2816\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3492\n",
      "Epoch: 2/30 Train Loss: 0.0138 Acc: 0.3426\n",
      "Begin test......\n",
      "Test Loss: 0.0130 Acc: 0.3982\n",
      "Epoch: 3/30 Train Loss: 0.0136 Acc: 0.3600\n",
      "Begin test......\n",
      "Test Loss: 0.0130 Acc: 0.3890\n",
      "Epoch: 4/30 Train Loss: 0.0133 Acc: 0.3728\n",
      "Begin test......\n",
      "Test Loss: 0.0130 Acc: 0.3948\n",
      "Epoch: 5/30 Train Loss: 0.0132 Acc: 0.3831\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4182\n",
      "Epoch: 6/30 Train Loss: 0.0124 Acc: 0.4215\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4489\n",
      "Epoch: 7/30 Train Loss: 0.0122 Acc: 0.4364\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4470\n",
      "Epoch: 8/30 Train Loss: 0.0120 Acc: 0.4406\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.4747\n",
      "Epoch: 9/30 Train Loss: 0.0120 Acc: 0.4429\n",
      "Begin test......\n",
      "Test Loss: 0.0116 Acc: 0.4754\n",
      "Epoch: 10/30 Train Loss: 0.0119 Acc: 0.4484\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4913\n",
      "Epoch: 11/30 Train Loss: 0.0113 Acc: 0.4739\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5026\n",
      "Epoch: 12/30 Train Loss: 0.0112 Acc: 0.4843\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5125\n",
      "Epoch: 13/30 Train Loss: 0.0112 Acc: 0.4842\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5276\n",
      "Epoch: 14/30 Train Loss: 0.0111 Acc: 0.4860\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5257\n",
      "Epoch: 15/30 Train Loss: 0.0111 Acc: 0.4864\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5089\n",
      "Epoch: 16/30 Train Loss: 0.0107 Acc: 0.5092\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5433\n",
      "Epoch: 17/30 Train Loss: 0.0107 Acc: 0.5085\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5511\n",
      "Epoch: 18/30 Train Loss: 0.0106 Acc: 0.5147\n",
      "Begin test......\n",
      "Test Loss: 0.0100 Acc: 0.5451\n",
      "Epoch: 19/30 Train Loss: 0.0105 Acc: 0.5159\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5499\n",
      "Epoch: 20/30 Train Loss: 0.0105 Acc: 0.5152\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5550\n",
      "Epoch: 21/30 Train Loss: 0.0103 Acc: 0.5283\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5619\n",
      "Epoch: 22/30 Train Loss: 0.0103 Acc: 0.5306\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5634\n",
      "Epoch: 23/30 Train Loss: 0.0102 Acc: 0.5294\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5662\n",
      "Epoch: 24/30 Train Loss: 0.0102 Acc: 0.5321\n",
      "Begin test......\n",
      "Test Loss: 0.0097 Acc: 0.5638\n",
      "Epoch: 25/30 Train Loss: 0.0102 Acc: 0.5334\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5655\n",
      "Epoch: 26/30 Train Loss: 0.0101 Acc: 0.5395\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5726\n",
      "Epoch: 27/30 Train Loss: 0.0101 Acc: 0.5394\n",
      "Begin test......\n",
      "Test Loss: 0.0096 Acc: 0.5742\n",
      "Epoch: 28/30 Train Loss: 0.0100 Acc: 0.5424\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5744\n",
      "Epoch: 29/30 Train Loss: 0.0099 Acc: 0.5456\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5705\n",
      "Epoch: 30/30 Train Loss: 0.0100 Acc: 0.5432\n",
      "Begin test......\n",
      "Test Loss: 0.0095 Acc: 0.5757\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0201, 0.0063, 0.0464, 0.3576, 0.0222, 0.3272, 0.0271, 0.0882, 0.0680,\n",
       "         0.0369]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "output = model(input.to(device))\n",
    "probabilities = F.softmax(output, dim=1)\n",
    "predict_label = torch.argmax(probabilities, dim=1)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.0201\n",
      "automobile: 0.0063\n",
      "bird: 0.0464\n",
      "cat: 0.3576\n",
      "deer: 0.0222\n",
      "dog: 0.3272\n",
      "frog: 0.0271\n",
      "horse: 0.0882\n",
      "ship: 0.0680\n",
      "truck: 0.0369\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[0][predict_label].item()\n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0][i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
