{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "# LEARNING_RATE = 1e-1\n",
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#执行这一行使用resnet\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = 10 # 替换为你的类别数\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0082 Acc: 0.6350\n",
      "Begin test......\n",
      "Test Loss: 0.0075 Acc: 0.7060\n",
      "Epoch: 2/30 Train Loss: 0.0055 Acc: 0.7578\n",
      "Begin test......\n",
      "Test Loss: 0.0051 Acc: 0.7783\n",
      "Epoch: 3/30 Train Loss: 0.0048 Acc: 0.7902\n",
      "Begin test......\n",
      "Test Loss: 0.0049 Acc: 0.7941\n",
      "Epoch: 4/30 Train Loss: 0.0043 Acc: 0.8091\n",
      "Begin test......\n",
      "Test Loss: 0.0044 Acc: 0.8099\n",
      "Epoch: 5/30 Train Loss: 0.0040 Acc: 0.8228\n",
      "Begin test......\n",
      "Test Loss: 0.0043 Acc: 0.8206\n",
      "Epoch: 6/30 Train Loss: 0.0033 Acc: 0.8521\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8441\n",
      "Epoch: 7/30 Train Loss: 0.0031 Acc: 0.8618\n",
      "Begin test......\n",
      "Test Loss: 0.0038 Acc: 0.8382\n",
      "Epoch: 8/30 Train Loss: 0.0029 Acc: 0.8676\n",
      "Begin test......\n",
      "Test Loss: 0.0039 Acc: 0.8382\n",
      "Epoch: 9/30 Train Loss: 0.0028 Acc: 0.8738\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8489\n",
      "Epoch: 10/30 Train Loss: 0.0027 Acc: 0.8780\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8481\n",
      "Epoch: 11/30 Train Loss: 0.0024 Acc: 0.8940\n",
      "Begin test......\n",
      "Test Loss: 0.0035 Acc: 0.8581\n",
      "Epoch: 12/30 Train Loss: 0.0022 Acc: 0.9006\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8517\n",
      "Epoch: 13/30 Train Loss: 0.0022 Acc: 0.9013\n",
      "Begin test......\n",
      "Test Loss: 0.0036 Acc: 0.8543\n",
      "Epoch: 14/30 Train Loss: 0.0021 Acc: 0.9061\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8536\n",
      "Epoch: 15/30 Train Loss: 0.0020 Acc: 0.9091\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8549\n",
      "Epoch: 16/30 Train Loss: 0.0018 Acc: 0.9163\n",
      "Begin test......\n",
      "Test Loss: 0.0035 Acc: 0.8614\n",
      "Epoch: 17/30 Train Loss: 0.0017 Acc: 0.9208\n",
      "Begin test......\n",
      "Test Loss: 0.0036 Acc: 0.8607\n",
      "Epoch: 18/30 Train Loss: 0.0017 Acc: 0.9235\n",
      "Begin test......\n",
      "Test Loss: 0.0036 Acc: 0.8636\n",
      "Epoch: 19/30 Train Loss: 0.0017 Acc: 0.9250\n",
      "Begin test......\n",
      "Test Loss: 0.0036 Acc: 0.8593\n",
      "Epoch: 20/30 Train Loss: 0.0016 Acc: 0.9276\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8601\n",
      "Epoch: 21/30 Train Loss: 0.0015 Acc: 0.9319\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8599\n",
      "Epoch: 22/30 Train Loss: 0.0015 Acc: 0.9343\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8613\n",
      "Epoch: 23/30 Train Loss: 0.0014 Acc: 0.9342\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8621\n",
      "Epoch: 24/30 Train Loss: 0.0014 Acc: 0.9360\n",
      "Begin test......\n",
      "Test Loss: 0.0037 Acc: 0.8617\n",
      "Epoch: 25/30 Train Loss: 0.0014 Acc: 0.9382\n",
      "Begin test......\n",
      "Test Loss: 0.0038 Acc: 0.8647\n",
      "Epoch: 26/30 Train Loss: 0.0013 Acc: 0.9396\n",
      "Begin test......\n",
      "Test Loss: 0.0038 Acc: 0.8631\n",
      "Epoch: 27/30 Train Loss: 0.0013 Acc: 0.9405\n",
      "Begin test......\n",
      "Test Loss: 0.0038 Acc: 0.8630\n",
      "Epoch: 28/30 Train Loss: 0.0013 Acc: 0.9414\n",
      "Begin test......\n",
      "Test Loss: 0.0038 Acc: 0.8625\n",
      "Epoch: 29/30 Train Loss: 0.0012 Acc: 0.9432\n",
      "Begin test......\n",
      "Test Loss: 0.0039 Acc: 0.8639\n",
      "Epoch: 30/30 Train Loss: 0.0013 Acc: 0.9428\n",
      "Begin test......\n",
      "Test Loss: 0.0039 Acc: 0.8619\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal CNN Acc:0.5780\n",
    "#resnet18 Acc: 0.8647 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "\n",
    "# probabilities = model(input.to(device)).squeeze(0)\n",
    "probabilities = model(input.unsqueeze(0).to(device)).squeeze(0)#resnet18 need 4D input\n",
    "predict_label = torch.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.1829\n",
      "automobile: -3.1020\n",
      "bird: 0.0934\n",
      "cat: 7.6373\n",
      "deer: -2.0383\n",
      "dog: 1.9396\n",
      "frog: 1.5431\n",
      "horse: -0.8391\n",
      "ship: -1.0009\n",
      "truck: -2.8213\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[predict_label].item()\n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
